xzl: (parameters) are not traineable (pretrained)
    pretrained....

    input size: [1,47554]

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Model                                    --                        --
├─PretrainedModel: 1                     --                        --
│    └─ModuleList: 2-1                   --                        --
│    └─ModuleList: 2-2                   --                        --
├─ModuleList: 1-1                        --                        --
├─PretrainedModel: 1                     --                        --
│    └─ModuleList: 2-1                   --                        --
------xzl: 80 channels. a bunch of sinc & conv layers.. e.g. [80 filters,60,60]------
│    │    └─SincLayer: 3-1               [1, 80, 595]              (160)        # 36.41ms
│    │    └─Abs: 3-2                     [1, 80, 595]              --           # 0.19ms
│    │    └─MaxPool1d: 3-3               [1, 80, 298]              --           # 0.19ms
│    │    └─LeakyReLU: 3-4               [1, 80, 298]              --           # 0.07ms
│    │    └─Dropout: 3-5                 [1, 80, 298]              --           # 0.02ms
│    │    └─Conv1d: 3-6                  [1, 60, 298]              (24,060)     # 0.27ms
│    │    └─MaxPool1d: 3-7               [1, 60, 298]              --           # 0.11ms
│    │    └─LeakyReLU: 3-8               [1, 60, 298]              --           # 0.04ms
│    │    └─Dropout: 3-9                 [1, 60, 298]              --           # 0.02ms
│    │    └─Conv1d: 3-10                 [1, 60, 298]              (18,060)     # 0.17ms
│    │    └─MaxPool1d: 3-11              [1, 60, 298]              --           # 0.08ms
│    │    └─LeakyReLU: 3-12              [1, 60, 298]              --           # 0.03ms
│    │    └─Dropout: 3-13                [1, 60, 298]              --           # 0.01ms
│    │    └─NCL2NLC: 3-14                [1, 298, 60]              --           # 0.02ms
------cdq: 36.6ms in total------
------xzl: below phoneme RNN ... 2 layers stacked ------
│    │    └─GRU: 3-15                    [1, 298, 256]             (145,920)    # 26.56ms
│    │    └─RNNSelect: 3-16              [1, 298, 256]             --           # 0.02ms
│    │    └─Dropout: 3-17                [1, 298, 256]             --           # 0.03ms
│    │    └─Downsample: 3-18             [1, 149, 256]             --           # 1.7ms
│    │    └─GRU: 3-19                    [1, 149, 256]             (296,448)    # 23.87ms
│    │    └─RNNSelect: 3-20              [1, 149, 256]             --           # 0.01ms
│    │    └─Dropout: 3-21                [1, 149, 256]             --           # 0.02ms
│    │    └─Downsample: 3-22             [1, 75, 256]              --           # 11.89ms
│    └─Linear: 2-3                       [1, 75, 42]               10,794       # 7.18ms
------xzl: phoneme logits output.... cdq: 66.83ms in total------
------xzl: below word embeddings------
│    └─ModuleList: 2-2                   --                        --           # 
│    │    └─GRU: 3-23                    [1, 75, 256]              (296,448)    # 64.29ms
│    │    └─RNNSelect: 3-24              [1, 75, 256]              --           # 0.03ms
│    │    └─Dropout: 3-25                [1, 75, 256]              --           # 0.02ms
│    │    └─Downsample: 3-26             [1, 38, 256]              --           # 17.6ms
│    │    └─GRU: 3-27                    [1, 38, 256]              (296,448)    # 78.65ms
│    │    └─RNNSelect: 3-28              [1, 38, 256]              --           # 0.01ms
│    │    └─Dropout: 3-29                [1, 38, 256]              --           # 0.04ms
│    │    └─Downsample: 3-30             [1, 19, 256]              --           # 24.67ms
------xzl: word embeddings output (not one hot); cdq: 185.31ms in total------
├─ModuleList: 1-1                        --                        --       
│    └─GRU: 2-4                          [1, 19, 256]              296,448      # 6.78ms
│    └─RNNSelect: 2-5                    [1, 19, 256]              --           # 0.02ms
│    └─Dropout: 2-6                      [1, 19, 256]              --           # 0.03ms
│    └─Downsample: 2-7                   [1, 19, 256]              --           # 0.04ms
│    └─Linear: 2-8                       [1, 19, 24]               6,168        # 0.08ms
│    └─FinalPool: 2-9                    [1, 24]                   --           # 1.96ms
==========================================================================================
Total params: 1,390,954
Trainable params: 313,410
Non-trainable params: 1,077,544
Total mult-adds (M): 139.35
==========================================================================================
Input size (MB): 0.19
Forward/backward pass size (MB): 1.88
Params size (MB): 5.56
Estimated Total Size (MB): 7.64
==========================================================================================
xzl: phoneme logits after: torch.Size([75, 42])
phoneme indices tensor([21, 21,  0,  0,  0, 21, 28, 36, 36, 36, 36, 36, 36,  8,  3,  8,  8,  8,
        20, 12, 28, 28, 10, 10,  8, 12,  7,  7,  6,  6,  6,  6,  3, 11, 22, 22,
        22, 22,  8,  8, 13, 13, 13, 21, 28, 24, 24,  3,  3, 11, 20, 20, 31, 31,
        31, 31, 32, 32, 32, 32, 32, 10, 25, 25, 25,  3,  3,  3,  3,  3,  3, 21,
        21, 21, 21], device='cuda:0')
[['increase', 'heat', 'washroom']]


